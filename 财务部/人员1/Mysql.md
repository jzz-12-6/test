Mysql

# 1.基础篇

基本架构

Mysql分为Server层和存储引擎层

* Server层报告连接层、查询缓存、分析器、优化器、执行器等，以及所有内置函数（日期、时间、数学），以及所有跨存储引擎的功能都在这一层实现（存储过程、触发器、视图）
* 存储引擎层负责数据的存储和提取。架构模式是插件式，支持InnoDB、MyISAM、Memory等多个存储引擎。5.5.5开始InnoDB为默认存储引擎

## 1.一条查询语句过程

**连接器**

连接器负责跟客户端建立连接、获取权限、维持和管理连接

```mysql
mysql -h$ip -P$port -u$user -p
```

修改权限不会立即生效，需重新连接。如果没有后续动作，连接处于空闲状态，时间过长（由参数wait_timeout控制，默认8H）会自动断开。

使用过多长连接会导致OOM，Mysql在执行过程中临时使用的内存是管理在连接对象里面的。只有在连接断开后才会释放

1. 定期断开长连接
2. 如果版本大于5.7，每执行一个比较大的操作后，执行mysql_reset_connection来重新初始化连接资源。不需要重连和验证权限，会将连接状态恢复到刚创建完的状态

**查询缓存**

MySQL拿到一个查询请求后、会先到查询缓存看看

8.0以后没有查询缓存的功能

**分析器**

```mysql
select * from t where Id = id
```

先做“词法分析”，识别出字符串是什么，代表什么。然后语法分析，判断SQL语句是否满足MySQL语法

**优化器**

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，确定各个表的连接顺序

**执行器**

开始执行的时候，先判断是否对表有查询的权限，无权限返回没有权限的错误。如果命中查询缓存，会在查询返回结果的时候，做权限验证。

如果有权限，打开表继续执行。打开表的时候，执行器根据表的引擎定义，使用这个引擎提供的接口，查询ID字段，假如没有索引：

1. 调用InnoDB引擎接口取这个表的第一行，判断ID值是否等于10，不是则跳过，是则存在结果集中；
2. 调用引擎接口取下一行，重复相同的逻辑判断，直到取到值
3. 执行器将上述遍历过程中所有满足条件的行组成的

  如果有索引，第一次调用满足条件的第一行，后面类似

rows_examined 字段记录扫描多少行

## 2.一条SQL更新语句是如何执行的

```sql
create table T (ID int primary,c int);
update T set c=c+1 where ID =2;
```

更新流程涉及重要的日志模块，redo log（重做日志）和binlog（归档日志）

**redo** **log**

WAL（Write-Ahead Logging）技术，先写日志，再写磁盘。

当一条记录需要更新的时候，InnoDB引擎先把记录写到redo log，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面。

InnoDB的redo log是固定大小的，当写满之后，会暂停更新，将日志写到磁盘，即使数据库发生异常重启，之前提交的记录也不会丢失，能力称为crash-safe

InnoDB引擎特有的日志。 innodb_flush_log_at_trx_commit 参数设置1，表示每次事务的redo log都持久化到磁盘

**binlog**

Server层日志

MySQL最开始并没有InnoDB引擎。自带引擎为MyISAM，但是MyISAM没有crash-safe能力，binlog只能用于归档。

两种日志不同：

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层特有的，所有引擎都可用
2. redo log是物理日志，记录的是在”某个数据页上做了什么修改“，binlog是逻辑日志，记录的是这个语句的原始逻辑，比如”给id=2这一行的c字段+1“
3. red log 是循环写的，空间固定会用完，binlog是可以追加写入的，文件写满后，会切换下一个文件读写

执行器和InnoDB引擎执行update语句流程

1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用搜索树找到这一行，如果ID=2这一行在内存中，就直接返回给执行器；否则，需要从磁盘读入内存，然后在返回
2. 执行器拿到引擎的行数据，把这个值+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log 处于prepare状态。然后告知执行器执行完成，随时可以提交事务
4. 执行器生成这个操作的binlog，并把binlog写入磁盘
5. 执行器调用引擎的提交事务接口，引擎把刚写入的redo log改成提交（commit）状态，更新完成

 sync_binlog 参数设置为1，每次事务的 binlog 都持久化到磁盘

**两阶段提交**（prepare、commit）

为什么需要两阶段提交？

redo log 和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致

## 3 事务隔离

在MySQL中，事务支持是在引擎层实现的，InnoDB支持事务，MyISAM不支持

**隔离性与隔离级别**

ACID（原子性、一致性、隔离性、持久性）

多个事务同时执行可能出现脏读、不可重复读、幻读

SQL标准的事务隔离级别：

* 读未提交：一个事务还没提交，做的变更被其他事务看到
* 读已提交：一个事务提交之后，做的变更被其他事务看到；MySQL默认级别
* 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数是一致的
* 串行化：出现读写冲突涩，后访问的事务必须等前一个事务执行完成，才继续执行

**事务隔离的实现**

在MySQL中，每条记录在更新的时候都会同时记录一条回滚操作，当没有事务需要这个回滚日志时，回滚日志会被删除。when?当系统里没有比这个回滚日志更早的read-view的时候。

为什么不使用长事务？

长事务意味系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录必须保留，会导致占用存储空间

**事务的启动方式**

1. 显示启动语句，begin或者start transaction。提交commit，回滚rollback
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。如果你只执行一个select语句，这个事务就启动了，事务持续存在直到执行commit或rollback

## 4 深入浅出索（上）

索引的出现是为了提高数据查询的效率，类似书的目录

**索引的常见模型**

* 哈希表，试用于等值查询，比如NoSQL引擎
* 有序数组，试用于静态存储引擎
* 搜索树

InnoDB的一个整数字段索引为列，N叉树的N差不多为1200。当树高度为4时，可以存储1200的3次方个值，大约17亿，树根的数据总在内存中，一个10亿的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘

**InnoDB** **的索引模型**

在 InnoDB 中，表都是根据主键顺序以索引的形式存放，这种存储方式的表称为索引组织表。InnoDB 使用了 B+ 树索引模型，每一个索引在 InnoDB 里面对应一棵 B+ 树

根据叶子节点的内容，索引类型分主键索引和非主键索引

主键索引（聚簇索引）的叶子节点存的是整行数据。非主键索引（二级索引）的叶子节点内容是主键的值

基于主键索引和普通索引的查询有什么区别？

如果直接查询主键，只需要搜索ID的B+树，如果普通索引，先查询普通索引的B+树，找到对应ID，在到ID索引树搜索一次。这个过程称为回表

**索引维护**

主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小

重建索引：alter table T engine=InnoDB

## 5 深入浅出索引（下）

**覆盖索引**

select ID from T where k between 3 and 5，只需要查询ID的值，ID的值已经在K索引树上了，索引K已经覆盖了我们的查询需求，称为覆盖索引

**最左前缀原则**

有了 (a,b)这个联合索引后，一般就不需要单独在 a 上建立索引了。

**索引下推**

5.6引入的索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤不满足条件的记录，减少回表次数。

比如name和age联合索引，查询

```mysql
select * from tuser where name like '张 %' and age=10 and ismale=1;
```

## 06 全局锁和表锁

根据加锁的范围，MySQL里面的锁大致可以分为全局锁、表级锁和行锁三类。

**全局锁**

全局锁是对整个数据库实例加锁。方法Flush tables with read lock;使用场景，全库做逻辑备份

官方自带的逻辑备份工具是 mysqldump。当mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图，single-transaction只适用于所有的表使用事务引擎的库；

为什么不使用 set global readonly=true 的方式呢？

一是，在有些系统中，readonly 的值会被用来做其他辑，比如用来判断一个库是主库还是备库。

二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，
那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 态，这样会导致整个库长时间处于不可写状态，

**表级锁**

MySQL里面的表级别的锁有两种：一种是表锁，一种元数据锁（MDL）

表锁的语法是 lock tables … read/write。可以用 unlock tables 主动
释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。5.5版本引入了MDL，当对一个表做增删改查操作的时候，加 MDL读锁；当要对表做结构变更操作的时候，加 MDL 写锁，读锁之间不互斥，读写锁之间、写锁之间是互斥的

如何安全地给小表加字段？

在 alter table
语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。

## 07  行锁功过：怎么减少行锁对性能的影响？

MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎就不支持，InnoDB支持

**两阶段锁**	

在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻
释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

**死锁和死锁检测**

出现死锁以后，有两种策略：

​	一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。默认时间50s；

​    另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。   	死锁检索要耗费大量的CPU资源，解决方法？

​	1.你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。

​	2.控制并发度，并发控制可以控制在中间件，或者源码底层，或者业务逻辑

## 08 | 事务到底是隔离的还是不隔离的？

在 MySQL 里，有两个“视图”的概念

* 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。
* 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。

**“快照”在 MVCC 里是怎么工作的？**

InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时
候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。

而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。

也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。

# 2 实践篇

## 09 | 普通索引和唯一索引，应该怎么选择？

**查询过程**

假设，执行查询的语句是 select id from T where k=5。

对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直
到碰到第一个不满足 k=5 条件的记录。
对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止
继续检索。

两者的性能微乎其微。

**更新过程**

change buffer

​		当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。

​		虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

​		将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭
（shutdown）的过程中，也会执行 merge 操作。

什么条件下可以使用 change buffer 呢？

​	唯一索引，所有的更新操作，需要先进行判断，会将数据读入内存，所以不需要change buffer，只能普通索引使用。

   当更新目标是普通索引，且不再内存中时，会提升访问速度。

**change buffer 的使用场景**

​		对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时
change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

​		假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新
先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。
这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。

**索引选择和实践**

普通索引和唯一索引在查询能力上是没差别的，主要考虑的是对更新性能的影响

**change buffer 和 redo log**

redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。

## 10 | MySQL为什么有时候会选错索引？

**优化器的逻辑**

优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句；扫描行数是影响执行代价的因素之一

扫描行数是怎么判断的？

MySQL根据索引的“区分度”来估算记录数；，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。使用 show index 方法，看到一个索引的基数；

MySQL 是怎样得到索引的基数的呢？

采样统计，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个
平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。，当变更的数据行数超过1/M 的时候，会自动触发重新做一次索引统计。

参数 innodb_stats_persistent

* 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
* 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，analyze table t 命令修正

**索引选择异常和处理**

1. 采用 force index 强行选择一个索引。
2. 修改SQL语句，确保命中正确索引
3. 新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

## 11 | 怎么给字符串字段加索引？

​		MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引；默认
地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。

​		使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询
成本。

​		如何确定长度？

​		索引区分度

```mysql
select count(distinct email) as L from SUser;
--依次选取不同长度的前缀来看这个值，
select
count(distinct left(email,4)）as L4,
count(distinct left(email,5)）as L5,
count(distinct left(email,6)）as L6,
count(distinct left(email,7)）as L7,
from SUser;
```

当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。适用于邮箱

**前缀索引对覆盖索引的影响**

使用前缀索引就用不上覆盖索引对查询性能的优化，需要回表

**其他方式**

​		如果是身份证号码，前面6位可能相同，需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。

​		第一种方式是使用倒序存储。身份证后6位没有前6位地址一样的重复逻辑

​		第二种方式是使用 hash 字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。

两种方式的异同点

​	相同点：都不支持范围查询

​	区别：

1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。
2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。
3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

## **12 | 为什么我的MySQL会“抖”一下？**

**你的 SQL 语句为什么变“慢”了**

​		当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

​		当更新操作变慢时，可能就是在刷脏页（flush）

1. InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。
2. 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
3. MySQL 认为系统“空闲”的时候。
4. MySQL 正常关闭的情况

InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：

1. 还没有使用的；
2. 使用了并且是干净页；
3. 使用了并且是脏页。

​     InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。

​	以下这两种情况，都是会明显影响性能的：

1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。

**InnoDB 刷脏页的控制策略**

​		参数innodb_io_capacity，它会告诉 InnoDB 你的磁盘能力。。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试。可能导致的问题MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。

  参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字F1(M)，InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。

​		要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏
页比例，不要让它经常接近 75%。

​		脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的

## 13 | 为什么表数据删掉一半，表文件大小不变？

一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。

**参数 innodb_file_per_table**

* OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起。
* ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。

**数据删除流程**

假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。

如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。

不止是删除数据会造成空洞，插入数据也会。

**重建表**

可以收缩表空间，alter table A engine=InnoDB 命令来重建表。

MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。引入了 Online DDL 之后，重建表的流程：

1. 建立一个临时文件，扫描表 A 主键的所有数据页；
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
5. 用临时文件替换表 A 的数据文件。

上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。

**Online 和 inplace**

1. DDL 过程如果是 Online 的，就一定是 inplace 的；
2. 反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。

## 14 | count(*)这么慢，我该怎么办？

**count(*) 的实现方式**

* MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；
* InnoDB 引擎执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。

MyISAM 表虽然 count(*) 很快，但是不支持事务；
show table status 命令虽然返回很快，但是不准确；
InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。

**不同的 count 用法**

count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。
所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。

至于分析性能差别的时候，你可以记住这么几个原则：
1. server 层要什么就给什么；
2. InnoDB 只给必要的值；
3. 现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有
做。

1. 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
2. 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。比count(主键快)，不会解析数据化以及拷贝字段值的操作

对于 count(字段) 来说：

1. 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
2. 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。

但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是 null，按行累加。

结论是：按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(*)

## **16 | “order by”是怎么工作的？**

**全字段排序**

Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。

```mysql
select city,name,age from t where city='杭州' order by name limit 1000;
```

语句执行流程

1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到 city 的值不满足查询条件为止；
6. 对 sort_buffer 中的数据按照字段 name 做快速排序；
7. 按照排序结果取前 1000 行返回给客户端。

sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。

```mysql
/* 打开 optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 
 
/* @a 保存 Innodb_rows_read 的初始值 */
select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';
 
/* 执行语句 */
select city, name,age from t where city='杭州' order by name limit 1000; 
 
/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
 
/* @b 保存 Innodb_rows_read 的当前值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';
 
/* 计算 Innodb_rows_read 差值 */
select @b-@a;
```

这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从
number_of_tmp_files 中看到是否使用了临时文件。

```mysql
"filesort_summary":{
	"rows":4000,
	"examined_rows":4000,(参与排序数量)
	"number_of_tmp_files":12,
	"sort_buffer_size":32664,
	"sort_mode":"<sort_key,packed_additional_fields排序过程对字符串做了“紧凑”处理。
}
```

**rowid 排序**

max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

排序过程如下

1. 初始化 sort_buffer，确定放入两个字段，即 name 和 id；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到不满足 city='杭州’条件为止
6. 对 sort_buffer 中的数据按照字段 name 进行排序；
7. 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。

这个时候执行 select @b-@a这个语句的值变成 5000 了,因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit1000，因此会多读 1000 行。

```mysql
"filesort_summary":{
	"rows":4000,
	"examined_rows":4000,(参与)
	"number_of_tmp_files":10,
	"sort_buffer_size":32664,
	"sort_mode":"<sort_key,rpwid>。
}
```

**全字段排序 VS rowid 排序**

MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。

如果内存够，就要多利用内存，尽量减少磁盘访问。

如果建立city 和 name 的联合索引，就不需要进行排序

创建一个 city、name 和 age 的联合索引，不需要回表

## 17 | 如何正确地显示随机消息？

**内存临时表**

```mysql
select word from words order by rand() limit 3;
```

Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。

执行流程如下：

1. 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。
2. 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand()函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的R 和 W 字段中，到此，扫描行数是 10000。
3. 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段R 排序。
4. 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。

5. 从内存临时表中一行一行地取出 R 值和位置信息，分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。

6. 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。
7. 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。

位置信息：

MySQL 的表是用什么方法来定位“一行数据”的。

如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。

对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；

对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；

order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。

**磁盘临时表**

tmp_table_size 这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。

磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。

MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。

而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：
1. 对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；
2. 取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个(R,rowid) 从堆中去掉，换成 (R’,rowid’)；
2. 重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。

**随机排序方法**

方法一：

1. 取得这个表的主键 id 的最大值 M 和最小值 N;
2. 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;
3. 取不小于 X 的第一个 ID 的行。

这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的select 也可以用索引快速定位，可以认为就只扫描了 3 行。因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。

方法二：

1. 取得整个表的行数，并记为 C。
2. 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。
3. 再用 limit Y,1 取得一行。

MySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。

方法三：

1. 取得整个表的行数，记为 C；
2. 根据相同的随机方法得到 Y1、Y2、Y3；
3. 再执行三个 limit Y, 1 语句得到三行数据。

## 18 | 为什么这些SQL语句逻辑相同，性能却差异巨大？

**案例一：条件字段函数操作**

对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。

**案例二：隐式类型转换**

```mysql
select * from tradelog where tradeid=110717;
--在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。以上语句相当于
select * from tradelog where CAST(tradid AS signed int) = 110717;

```

**案例三：隐式字符编码转换**

字符集不同就用不上索引,连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。

## 19 | 为什么我只查一行的语句，也执行这么慢？

**第一类：查询长时间不返回**

1. 等 MDL 锁
2. 等 flush
3. 等行锁

**第二类：查询慢**

1. 未走索引
2. 等行锁

## **20 | 幻读是什么，幻读有什么问题？**

###  1.幻读是什么**

1. 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。
2. 上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。

### **2.幻读有什么问题？**

1. 语义被破坏
2. 数据一致性的问题

### 3.如何解决幻读？

产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。

在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。

行锁，分成读锁和写锁。跟行锁有冲突关系的是“另外一个行锁”。跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。

间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。实现上，InnoDB 给每个索引加了一个不存在的最大值supremum，这样才符合我们前面说的“都是前开后闭区间”。

间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的；间隙锁是在可重复读隔离级别下才会生效的。

你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。

## 21 | 为什么我只改一行的语句，锁这么多？

1. MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 <=5.7.24，8.0 系列 <=8.0.13。
2. 因为间隙锁在可重复读隔离级别下才有效，若没有特殊说明，默认是可重复读隔离级别。

### 1加锁规则

1. 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
2. 原则 2：查找过程中访问到的对象才会加锁。
3. 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。
4. 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，nextkeylock 退化为间隙锁。
5. 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

## 22 | MySQL有哪些“饮鸩止渴”提高性能的方法？

### 1.短连接风暴

max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。

如何处理：

1. 先处理掉那些占着连接但是不工作的线程。

max_connections 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过 kill connection 主动踢掉。这个行为跟事先设置wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。

2. 减少连接过程的消耗。

让数据库跳过权限验证阶段。方法是：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。

在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 --skipnetworking参数打开，表示这时候数据库只能被本地的客户端连接。

### 2.慢查询性能问题

三种可能：

#### 1.索引没有设计好；

紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持Online DDL 了。

执行流程：

1. 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句
加上索引；
2. 执行主备切换；
3. 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table
语句加上索引。

平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。

#### 2.SQL 语句没写好；

通过改写SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。

比如语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。

```mysql
mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");

--存储过程，是让插入的新规则生效
call query_rewrite.flush_rewrite_rules();

```

#### 3.MySQL 选错了索引。

应急方案就是给这个语句加上 force index。使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。

#### 4.预防问题

1. 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置
成 0，确保每个语句都会被记录入慢查询日志；
2. 在测试表里插入模拟线上的数据，做一遍回归测试；
3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。
4. 使用开源工具 pt-querydigest

### 3.QPS 突增问题

 QPS：Queries-per-second； 每秒查询率 

如何解决？

1. 一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。

2. 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。

3. 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成"select 1"返回。

  副作用：

  1. 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；
  2. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1的结果返回的话，可能会导致后面的业务逻辑一起失败。

## 23 | MySQL是怎么保证数据不丢的？

只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。

### 1.binlog 的写入机制

binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。

系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

每个线程有自己 binlog cache，但是共用同一份 binlog 文件。write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。

write 和 fsync 的时机，是由参数 sync_binlog 控制的：
1. sync_binlog=0 的时候，表示每次提交事务都只 write，不fsync；
2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
3. sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才fsync。

因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N个事务的 binlog 日志。

### 2.redo log的写入机制

事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。

#### 1.redo log 可能存在的三种状态

1. 存在 redo log buffer 中，物理上是在 MySQL 进程内存中
2. 写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面
3. 持久化到磁盘，对应的是 hard disk

日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。

InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：

1. 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;
2. 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；
3. 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。

有两种场景会让一个没有提交的事务的redo log 写入到磁盘中。

1. 一种是，redo log buffer 占用的空间即将达到innodb_log_buffer_size 一半的时候，后台线程会主动写盘
2. 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。

MySQL 的“双 1”配置，指的就是 sync_binlog 和
innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。

### **2.组提交（group commit）机制**

日志逻辑序列号（log sequence number，LSN）的概念：LSN
是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。

三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log
buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和160。

1. trx1 是第一个到达的，会被选为这组的 leader；
2. 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了160；
3. trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于160 的 redo log，都已经被持久化到磁盘；
4. 这时候 trx2 和 trx3 就可以直接返回了。

如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay
和 binlog_group_commit_sync_no_delay_count 来实现。
1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用fsync。

WAL 机制主要得益于两个方面：
1. redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度快；
2. 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。

### 3.MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？

1. 设置 binlog_group_commit_sync_delay 和
binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。
2. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。
3. 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

## 24 | MySQL是怎么保证主备一致的？

### 1.MySQL 主备的基本原理

#### 1.主备切换流程

一个客户端一个主库（节点A）一个从库（节点B，只读模式）

未切换之前，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。

切换之后客户端读写访问的都是节点 B，而节点 A 是 B的备库。

为什么将从库设为只读模式？

1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
2. 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；
3. 可以用 readonly 状态，来判断节点的角色。

备库设置成只读了，还怎么跟主库保持同步更新呢？因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

#### 2.节点 A 到 B 这条线的内部流程

一个事务日志同步的完整过程是这样的：

1. 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
2. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread和 sql_thread。其中 io_thread 负责与主库建立连接。
3. 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
4. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
5. sql_thread 读取中转日志，解析出日志里的命令，并执行。

### 2.binlog 的三种格式对比

执行删除语句

1. statement

   binlog 里面记录的就是 SQL 语句的原文。

2. row

   row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map（操作库） 和 Delete_rows（删除的行为）。binlog 里面记录了真实删除行的主键 id

3. mixed

   因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。

   mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用row 格式，否则就用 statement 格式。

### 3.恢复数据

越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。

1. delete

   row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。

2. insert

   row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把
   insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。

3. update

   binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。

### 4.循环复制问题

一般MySQL总是互为主备，这样在切换的时候就不用再修改主备关系。

业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。

如何解决？

1. 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；
2. 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的binlog；
3. 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。

## 25 | MySQL是怎么保证高可用的？

### 1.主备延迟

同步延迟：

1. 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;

2. 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;

3. 备库 B 执行完成这个事务，我们把这个时刻记为 T3。

   所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。

在备库上执行 show slave status 命令，它的返回结果里面会显示
seconds_behind_master，用于表示当前备库延迟了多少秒。

1. 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；
2. 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到seconds_behind_master。

### 2.主备延迟的来源

1. 备库所在机器的性能要比主库所在的机器性能差。

2. 备库的压力大

   处理方式：

   1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
   2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的
   能力。

3. 大事务

   如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10分钟。场景：一次性地用 delete 语句删除太多数
   据；大表 DDL

4. 备库的并行复制能力

### 3.可靠性优先策略

双 M 结构切换流程：

1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
2. 把主库 A 改成只读状态，即把 readonly 设置为 true；
3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
4. 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
5. 把业务请求切到备库 B。

在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。

### 4.可用性优先策略

如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。

## 26 | 备库为什么会延迟好几个小时？

## 28 | 读写分离有哪些坑？

一主多从的结构，其实就是读写分离的基本结构

### 1.两种架构：

* 是客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。
* 在 MySQL 和客户端之间有一个中间代理层 proxy，客户端只连接proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由。

特点：

1. 客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。
2. 带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。

由于主从可能存在的延迟客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。

解决方案如下：

1. 强制走主库方案；
2. sleep 方案；
3. 判断主备无延迟方案；
4. 配合 semi-sync 方案；
5. 等主库位点方案；
6. 等 GTID 方案。

#### 1.1 强制走主库方案

强制走主库方案其实就是，将查询请求做分类。

1. 对于必须要拿到最新结果的请求，强制将其发到主库上。
2. 对于可以读到旧数据的请求，才将其发到从库上。

方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。

### 1.2 Sleep 方案

主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令。

这个方案的假设是，大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据。但是可能不精确。

1. 如果这个查询请求本来 0.5 秒就可以在从库上拿到正确结果，也会等 1 秒；
2. 如果延迟超过 1 秒，还是会出现过期读。

#### 1.3 判断主备无延迟方案

show slave status 结果里的seconds_behind_master 参数的值，可以用来衡量主备延迟时间的长短。

方法一：每次从库执行查询请求前，先判断seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为0 才能执行查询请求。

show slave status 结果

```mysql
Master_Log_File:master.000012
Read_Master_Log_Pos:126067593
--以上表示读到的主库的最新位点
.....
Relay_Master_Log_File:master.000012
Exec_Master_Log_Pos:126067593
--以上表示备库执行的最新位点
.....
Retrieved_Gtid_Set:000000-111-000:1-1000
--备库收到的所有日志的 GTID 集合；
Executed_Gtid_Set:000000-111-000:1-1000
--备库所有已经执行完成的 GTID 集合。
Auto_Position:1
--表示这对主备关系使用了 GTID 协议。
```

方法二：如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。

方法三：对比 GTID 集合确保主备无延迟，如果这两个集合相同，也表示备库接收到的日志都已经同步完成。

对比位点和对比 GTID 这两种方法，都要比判断seconds_behind_master 是否为 0更准确。

但是，从 binlog在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。

#### 1.4 配合 semi-sync

要解决上述问题，就要引入半同步复制，也就是 semi-sync replication。

semi-sync 做了这样的设计：
1. 事务提交的时候，主库把 binlog 发给从库；
2. 从库收到 binlog 以后，发回给主库一个 ack，表示收到了；
3. 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。

semi-sync 配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。但是，semi-sync+ 位点判断的方案，只对一主一备的场景是成立的。

semi-sync 配合判断主备无延迟的方案，存在两个问题：

1. 一主多从的时候，在某些从库执行查询请求会存在过期读的现象；
2. 在持续延迟的情况下，可能出现过度等待的问题。

#### 1.5 等主库位点方案

```mysql
select master_pos_wait(file, pos[, timeout]);
```

这条命令的逻辑如下：
1. 它是在从库执行的；
2. 参数 file 和 pos 指的是主库上的文件名和位置；
3. timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。

命令返回结果：

1. 一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表
   示的 binlog 位置，执行了多少事务。
2. 如果执行期间，备库同步线程发生异常，则返回 NULL；
3. 如果等待超过 N 秒，就返回 -1；
4. 如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。

执行流程：

1. trx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和Position；
2. 选定一个从库执行查询语句；
3. 在从库上执行 select master_pos_wait(File, Position, 1)；
4. 如果返回值是 >=0 的正整数，则在这个从库执行查询语句；
1 select master_pos_wait(file, pos[, timeout]);
5. 否则，到主库执行查询语句。

#### 1.6 GTID 方案

```mysql
select wait_for_executed_gtid_set(gtid_set, 1);
```

这条命令的逻辑是：
1. 等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；
2. 超时返回 1。

而 MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。

等 GTID 的执行流程就变成了：
1. trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；
2. 选定一个从库执行查询语句；
3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；
4. 如果返回值是 0，则在这个从库执行查询语句；
5. 否则，到主库执行查询语句。

参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口
mysql_session_track_get_first 从返回包解析出 GTID 的值即可。

## 29 | 如何判断一个数据库是不是出问题了？

### 1 select 1 判断

select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。

在 InnoDB 中，innodb_thread_concurrency 这个参数的默认值是 0，表示不限制并发线程数量。建议把 innodb_thread_concurrency 设置为 64~128 之间的值

并发连接和并发查询。

在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。

在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 128 里面的。

### 2 查表判断

在系统库（mysql 库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行：

```mysql
select * from mysql.health_check;
```

空间满了以后，这种方法又会变得不好使。更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。

### 3 更新判断

```mysql
update mysql.health_check set t_modified=now();
```

节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。

还会有判定慢的问题.原因：

服务器 IO 资源分配的问题，所有的检测逻辑都需要一个超时时间N。执行一条 update 语句，超过 N 秒后还不返回，就认为系统不可用。

设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。，IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。这时候在业务系统上正常的 SQL 语句已经执行得很慢了。

上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。

### 4 内部统计

MySQL 5.6 版本以后提供的 performance_schema 库，就在
file_summary_by_event_name 表里统计了每次 IO 请求的时间。

```mysql
SELECT * FROM file_summary_by_event_name WHERE
EVENT_NAME = "wait/io/file/innodb/innodb_log_file"
--这一行统计的是 redo log 的写入时间，第一列 EVENT_NAME 表示统计的类型。
```

| 列                        | 值                                  |                                |
| ------------------------- | ----------------------------------- | ------------------------------ |
| EVENT_NAME                | wait/io/file/innodb/innodb_log_file | 统计的是 redo log 的写入时间   |
| COUNT_STAR                | 21                                  | 所有 IO 类型的统计（IO总次数） |
| SUM_TIMER_WAIT            | 962747194868                        |                                |
| MIN_TIMER_WAIT            | 10273092                            |                                |
| AVG_TIMER_WAIT            | 45845104348                         |                                |
| MAX_TIMER_WAIT            | 175712226876                        |                                |
| COUNT_READ                | 7                                   | 读操作统计                     |
| SUM_TIMER_READ            | 342860919320                        |                                |
| MIN_TIMER_READ            | 221776608                           |                                |
| AVG_TIMER_READ            | 48980131128                         |                                |
| MAX_TIMER_READ            | 159060956996                        |                                |
| SUM_NUMBER_OF_BYTES_READ  | 70144                               | 从 redo log 里读了多少个字节   |
| COUNT_WRITE               | 4                                   | 写操作统计                     |
| SUM_TIMER_WRITE           | 1982846664                          |                                |
| MIN_TIMER_WRITE           | 39029348                            |                                |
| AVG_TIMER_WRITE           | 495711488                           |                                |
| MAX_TIMER_WRITE           | 1714835268                          |                                |
| SUM_NUMBER_OF_BYTES_WRITE | 2048                                |                                |
| COUNT_MISC                | 10                                  | 其他类型数据的统计             |
| SUM_TIMER_MISC            | 617903428884                        |                                |
| MIN_TIMER_MISC            | 10273092                            |                                |
| AVG_TIMER_MISC            | 61790342568                         |                                |
| MAX_TIMER_MISC            | 175712226876                        |                                |

binlog 对应的是event_name = "wait/io/file/sql/binlog"这一行。各个字段的统计逻辑，与 redo log 的各个字段完全相同。

我们每一次操作数据库，performance_schema 都需要额外地统计这些信息，所以我
们打开这个统计功能是有性能损耗的。如果打开所有的 performance_schema 项，性能大概会下降 10% 左右。建议你只打开自己需要的项进行统计。

```mysql
update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';
--打开 redo log 的时间监控
```

可以通过 MAX_TIMER 的值来判断数据库是否出问题了。比如，你可以设定阈值，单次 IO 请求时间超过 200 毫秒属于异常。

```mysql
select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;
--检测逻辑
truncate table performance_schema.file_summary_by_event_name;
--清空之前的统计信息清空
```

## 31 | 误删数据后除了跑路，还能怎么办？

误删数据分类

1. 使用 delete 语句误删数据行；
2. 使用 drop table 或者 truncate table 语句误删数据表；
3. 使用 drop database 语句误删数据库；
4. 使用 rm 命令误删整个 MySQL 实例。

### 1 误删行

如果是使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。

Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。

单个事务处理如下：

1. 对于 insert 语句，对应的 binlog event 类型是 Write_rows event，把它改成Delete_rows event 即可；
2. 同理，对于 delete 语句，也是将 Delete_rows event 改为 Write_rows event；
3. 而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。

多个事务：

多个事务的话，需要将事务的顺序调过来再执行。

恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。

如何预防误删：

1. 把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。
2. 代码上线前，必须经过 SQL 审计。

如何删除全表：

1. 可以在 delete 语句中加上 where 条件，比如where id>=0。
2. 使用 truncate table 或者 drop table 命令

### 2 误删库 / 表

使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog。
恢复数据的流程如下：
1. 取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；
2. 用备份恢复出一个临时库；
3. 从日志备份里面，取出凌晨 0 点之后的日志；
4. 把这些日志，除了误删除数据的语句外，全部应用到临时库。

-mysqlbinlog 方法

1. 为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。

2. 在应用日志的时候，需要跳过 12 点误操作的那个语句的binlog：

  如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；
  如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next=gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。

使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个：

1. 如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是mysqlbinlog 工具并不能指定只解析一个表的日志；
2. 用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。

如何加速：

1. 在 start slave 之前，先通过执行
change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表；
2. 这样做也可以用上并行复制技术，来加速整个数据恢复过程。

#### 2.2 延迟复制备库

MySQL 5.6 版本引入的功能

一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了。

延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。

比如你把 N 设置为 3600，这就代表了如果主库上有数据被误删了，并且在 1 小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。

### 3 预防误删库 / 表的方法

1. 账号分离。这样做的目的是，避免写错命令。

   业务开发同学 DML 权限，而不给 truncate/drop 权限；DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。

2. 制定操作规范。这样做的目的，是避免写错要删除的表名。

   在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。

### 4 rm 删除数据

只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。

## 32 | 为什么还有kill不掉的语句？

在 MySQL 中有两个 kill 命令：

* kill query + 线程 id，表示终止这个线程中正在执行的语句；
* 一个是 kill [connection] + 线程 id，表示断开这个线程的连接;

### 1 收到 kill 以后，线程做什么？

## 34 | 到底可不可以使用join？

### 1 Index Nested-Loop Join

```mysql
select * from t1 straight_join t2 on (t1.a=t2.a);
--t2表上a字段为索引
```

被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引,流程如下：

1. 从表 t1 中读入一行数据 R；

2. 从数据行 R 中，取出 a 字段到表 t2 里去查找；
3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；
4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。

在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。

在这个流程里：
1. 对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；
2. 而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都
3. 是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；
4. 所以，整个执行流程，总扫描行数是 200。

结论：前提是可以使用被驱动表的索引

1. 使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；
2. 如果使用 join 语句的话，需要让小表做驱动表。

### 2 Simple Nested-Loop Join

```mysql
select * from t1 straight_join t2 on (t1.a=t2.b);
--表 t2 的字段 b 上没有索引
```

每次到 t2 去匹配的时候，就要做一次全表扫描。这个算法也有一个名字，叫做“Simple Nested-Loop Join”。这样算来，这个 SQL 请求就要扫描表 t2 多达 100 次，总共扫描 100*1000=10 万行。

### 3 Block Nested-Loop Join(BNL)

被驱动表上没有可用的索引，算法的流程是这样的：

1. 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；
2. 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。

使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万
行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。

假设小表的行数是 N，大表的行数是 M，那么在这个算法里：
1. 两个表都做一次全表扫描，所以总的扫描行数是 M+N；
2. 内存中的判断次数是 M*N。

可以看到，调换这两个算式中的 M 和 N 没差别，因此这时候选择大表还是小表做驱动表，执行耗时是一样的。

join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1的所有数据话，策略很简单，就是分段放。

分段执行过程：

1. 扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；
2. 扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；
3. 清空 join_buffer；
4. 继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。

这个算法的执行过程中：

1. 扫描行数是 N+λ*N*M；（N小，扫描行数越少）
2. 内存判断 N*M 次。（不受驱动表影响）

 N 越大，分段数 K 越大。那么，N 固定的时候。join_buffer_size 越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。

能不能使用 join 语句？

1. 如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
2. 如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。

在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。

### 4 选择小表做驱动表

#### 4.1 什么叫作“小表“

在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

## 35 | join语句怎么优化？

```mysql
create table t1(id int primary key, a int, b int, index(a));
create table t2 like t1;
--示例表，t1表1000行数据，t21000000行数据
```

### 1 Multi-Range Read 优化

MRR这个优化的主要目的是尽量使用顺序读盘。

因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。

```mysql
select * from t1 where a>=1 and a<=100;
```

执行流程为:

1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
2. 将 read_rnd_buffer 中的 id 进行递增排序；
3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

这里，read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继
续找索引 a 的下个记录，并继续循环。

使用 MRR 优化的话，需要设置set
optimizer_switch="mrr_cost_based=off"。

MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询，可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。

### 2 Batched Key Access

BKA 算法，其实就是对 NLJ 算法的优化。

```mysql
--启动方法
set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
```

NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做join。也就是说，对于表 t2 来说，每次都是匹配一个值。

把表 t1 的数据取出来一部分，先放到join_buffer；

### 3 BNL 算法的性能问题

InnoDB 的 LRU 算法的时候提到，由于 InnoDB 对 Bufffer
Pool 的 LRU 算法做了优化，即：第一次从磁盘读入内存的数据页，会先放在 old 区域。如果 1 秒之后这个数据页不再被访问了，就不会被移动到 LRU 链表头部，这样对 Buffer Pool 的命中率影响就不大。

大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。

为了减少这种影响，你可以考虑增大 join_buffer_size 的值，减少对被驱动表的扫描次数。

BNL 算法对系统的影响主要包括三个方面：

1. 可能会多次扫描被驱动表，占用磁盘 IO 资源；
2. 判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会
占用非常多的 CPU 资源；
3. 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。

确认优化器会使用 BNL 算法，就需要做优化。优化的常见做法是，给被驱动表的 join 字段加上索引，把 BNL 算法转成 BKA 算法。

### 4 BNL 转 BKA

在原表上加索引，还是用有索引的临时表，我们的思路都是让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能。

### 5 扩展 -hash join

实现流程大致如下：

  1. select * from t1;取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构
 2. select * from t2 where b>=1 and b<=2000; 获取表 t2 中满足条件的 2000 行数据。
 3. 把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。

## 36 | 为什么临时表可以重名？

内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine=memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。

临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。

### 1 临时表的特性

1. 建表语法是 create temporary table …。
2. 一个临时表只能被创建它的 session 访问，对其他线程不可见。所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的。
3. 临时表可以与普通表同名。
4. session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。
5. show tables 命令不显示临时表。

临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表，也正是由于这个特性，临时表就特别适合我们文章开头的 join 优化这种场景。

1. 不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。
2. 不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。

### 2 临时表的应用

#### 2.1 分库分表系统的跨库查询

一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。

比如。将一个大表 ht，按照字段 f，拆分成 1024 个分表，然后分布到 32 个数据库实例上。

一般情况下，这种分库分表系统都有一个中间层 proxy。不过，也有一些方案会让客户端直接连接数据库，也就是没有 proxy 这一层。

分区 key 的选择是以“减少跨库和跨表查询”为依据的。

```mysql
select v from ht where f=N;
```

就可以通过分表规则（比如，N%1024) 来确认需要的数据被放在了哪个分表上。这种语句只需要访问一个分表，

```mysql
select v from ht where k >= M order by t_modified desc limit 100;
```

这时候，由于查询条件里面没有用到分区字段 f，只能到所有的分区中去查找满足条件的所有行，然后统一做 order by 的操作。这种情况下，有两种比较常用的思路。

方法一：在 proxy 层的进程代码中实现排序。

这种方式的优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算。不过，这个
方案的缺点也比较明显：
1. 需要的开发工作量比较大。我们举例的这条语句还算是比较简单的，如果涉及到复杂的操作，比如 group by，甚至 join 这样的操作，对中间层的开发能力要求比较高；
2. 对 proxy 端的压力比较大，尤其是很容易出现内存不够用和 CPU 瓶颈的问题。

方法二：把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。

在汇总库上创建一个临时表 temp_ht，表里包含三个字段 v、k、t_modified；
在各个分库上执行cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc

```mysql
select v,k,t_modified frcccccccccccccom ht_x where k >= M order by t_modified desc limit 100;
```

把分库执行的结果插入到 temp_ht 表中；

```mysql
select v from temp_ht order by t_modified desc limit 100;
```

### 3 为什么临时表可以重名？

```mysql
create temporary table temp_t(id int primary key)engine=innodb;
```

MySQL 要给这个 InnoDB 表创建一个 frm 文件保存表结构定义，还要有地方保存表数据。

这个 frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程 id}_{线程id}_ 序列号”。你可以使用 select @@tmpdir 命令，来显示实例的临时文件目录。

在 5.6 以及之前的版本里，MySQL 会在临时文件目录下创建一个相同前缀、以.ibd 为后缀的文件，用来存放数据文件；
而从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建 ibd 文件了。

   MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key。

* 一个普通表的 table_def_key 的值是由“库名 + 表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了。
* 临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。

在实现上，每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE表名”操作。

### 4 临时表和主备复制

如果当前的 binlog_format=row，那么跟临时表有关的语句，就不会记录到binlog 里。也就是说，只在 binlog_format=statment/mixed 的时候，binlog 中才会记录临时表的操作。

这种情况下，创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我们就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行。

MySQL 在记录 binlog 的时候，不论是 create table 还是 alter table 语句，都是原样记录，甚至于连空格都不变。但是如果执行 drop table t_normal,系统记录 binlog 就会写成：DROP TABLE `t_normal` /* generated by server */;

原因：备库上并没有表 temp_t，将这个命令重写后再传到备库执行，才不会导致备库同步线程停止。所以，drop table 命令记录 binlog 的时候，就必须对语句做改写。“/* generated by server */”说明了这是一个被服务端改写过的命令。

MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key：

1. session A 的临时表 t1，在备库的 table_def_key 就是：库名 +t1+“M 的serverid”+“session A 的 thread_id”;
2. session B 的临时表 t1，在备库的 table_def_key 就是 ：库名 +t1+“M 的serverid”+“session B 的 thread_id”。

## 37 | 什么时候会使用内部临时表？

### 1 union 执行流程

```mysql
create table t1(id int primary key, a int, b int, index(a));
(select 1000 as f) union (select id from t1 order by id desc limit 2);
-- explain 会使用index,temporary
```

语句的执行流程是:

1. 创建一个内存临时表，这个临时表只有一个整型字段 f，并且 f 是主键字段。

2. 执行第一个子查询，得到 1000 这个值，并存入临时表中。

3. 执行第二个子查询：

   拿到第一行 id=1000，试图插入临时表中。但由于 1000 这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；取到第二行 id=999，插入临时表成功。

4. 从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是 1000和 9999

#### 1.1 对比union all

```mysql
(select 1000 as f) union all (select id from t1 order by id desc limit 2);
-- union all 不会去重 ,explain 只使用index
```

这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。

### 2 group by 执行流程

```mysql
select id%10 as m, count(*) as c from t1 group by m;
-- explain using index;temporary;filesort
```

执行流程:

1. 创建内存临时表，表里有两个字段 m 和 c，主键是 m；

2. 扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x；

   如果临时表中没有主键为 x 的行，就插入一个记录 (x,1);
   如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；

3. 遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。

```mysql
select id%10 as m, count(*) as c from t1 group by m order by null;
-- order by null 表示不需要排序
```

参数 tmp_table_size 控制内存临时表大小的，默认是 16M。

如果返回结果超过内存临时表的大小，就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是 InnoDB。

#### 2.1 group by 优化方法 -- 索引

在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新。

```mysql
 alter table t1 add column z int generated always as(id % 100), add index(z);
```

generated column 是什么？ 数据库中这一列由其他列计算而得 

```mysql
select z, count(*) as c from t1 group by z;
-- using index 不需要临时表，也不需要排序
```

#### 2.2 group by 优化方法 -- 直接排序

在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个 语句涉及的数据量很大，请直接用磁盘临时表。

```mysql
 select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
 -- using index,filesort
```

执行流程：

1. 初始化 sort_buffer，确定放入一个整型字段，记为 m； 
2. 扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中；
3. 扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利 用磁盘临时文件辅助排序）
4. 排序完成后，就得到了一个有序数组。

### 3 MySQL 什么时候会使用内部临时表

1. 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就 需要额外的内存，来保存中间结果；
2. join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；
3.  如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中， union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数

### 4 小结

1. 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；
2. 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；
3. 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表； 
4. 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算 法得到 group by 的结果。



## 38 | 都说InnoDB好，那还要不要使用Memory引擎？

### 1 内存表的数据组织结构

```mysql
create table t1(id int primary key, c int) engine=Memory;
create table t2(id int primary key, c int) engine=innodb;
insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
select * from t1 ；
select * from t2 ；
```

内存表 t1 的返回结果里面 0 在最后一行，而 InnoDB 表 t2 的返回结果里 0 在第一行。

t2表用的InnoDB 引擎，它的主键索引 id 的组织方式，主键索引上的值是有序存储的。在执行 select * 的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0 就出现在第一行。

t1表用的Memory 引擎，数据和索引是分开的。内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。执行 select * 的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0 就是最后一个被读到，并放入结果集的数据。

InnoDB 和 Memory 引擎的数据组织方式是不同的：

* InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。
* Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。

异同点：

1. InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
2. 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
3. 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
4. InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
5. InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

### 2 hash 索引和 B-Tree 索引

```mysql
alter table t1 add index a_btree_index using btree (id);
-- 内存表也是支 B-Tree 索引的。在 id 列上创建一个 B-Tree 索引
select * from t1 where id < 5;
-- 优化器会选择B-TREE索引，所以结果返回0-4
select * from t1 force index(primary) where id < 5;
-- 强行使用主键，所以0在最后一行
```

### 3 内存表的锁

内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。

### 4 数据持久性问题

数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。

#### 4.1 M-S 架构下，使用内存表存在的问题。

下面这个时序：

1. 业务正常访问主库；
2. 备库硬件升级，备库重启，内存表 t1 内容被清空；
3. 备库重启后，客户端发送一条 update 语句，修改表 t1 的数据行，这时备库应用线程就会报错“找不到要更新的行”。

这样就会导致主备同步停止。当然，如果这时候发生主备切换的话，客户端会看到，表 t1的数据“丢失”了。

#### 4.2 双 M 结构下，使用内存表存在的问题。

由于 MySQL 知道重启之后，内存表的数据会丢失。所以，担心主库重启之后，出现主备不一致，在数据库重启之后，往 binlog 里面写入一行 DELETE FROM t1。

在备库重启的时候，备库 binlog 里的 delete 语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了。

建议你把普通内存表都用 InnoDB 表来代替；原因

1. 如果你的表更新量大，那么并发度是一个很重要的参考指标，InnoDB 支持行锁，并发度比内存表好；
2. 能放到内存表的数据量都不大。如果你考虑的是读的性能，一个读 QPS 很高并且数据量不大的表，即使是使用 InnoDB，数据也是都会缓存在 InnoDB Buffer Pool 里的。因此，使用 InnoDB 表的读性能也不会差。

### 5 用户临时表

在数据量可控，不会耗费过多内存的情况下，可以考虑使用内存表。

内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：
1. 临时表不会被其他线程访问，没有并发性的问题；
2. 临时表重启后也是需要删除的，清空数据这个问题不存在；
3. 备库的临时表也不会影响主库的用户线程。

## 39 | 自增主键为什么不是连续的？

### 1 自增值保存在哪儿？

```mysql
CREATE TABLE `t` (
`id` int(11) NOT NULL AUTO_INCREMENT,
`c` int(11) DEFAULT NULL,
`d` int(11) DEFAULT NULL,
PRIMARY KEY (`id`),
UNIQUE KEY `c` (`c`)
) ENGINE=InnoDB;
insert into t values(null, 1, 1);
-- 执行一行插入语句
show create table
Create Table： CREATE TABLE `t` (
`id` int(11) NOT NULL AUTO_INCREMENT,
`c` int(11) DEFAULT NULL,
`d` int(11) DEFAULT NULL,
PRIMARY KEY (`id`),
UNIQUE KEY `c` (`c`)
) ENGINE=InnoDB AUTO_INCREMENT=2;
-- AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2。
```

表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。

不同的引擎对于自增值的保存策略不同。

* MyISAM 引擎的自增值保存在数据文件中。

* InnoDB 引擎的自增值，其实是保存在了内存里

  在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。

  MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。

### 2 自增值修改机制

MySQL 里面，如果字段 id 被定义为 AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：

1. 如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的AUTO_INCREMENT 值填到自增字段；

2. 如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。

   某次要插入的值是 X，当前的自增值是 Y。

   1. 如果 X<Y，那么这个表的自增值不变；
   2. 如果 X≥Y，就需要把当前自增值修改为新的自增值。

#### 2.1 新的自增值生成算法

从 auto_increment_offset （自增的初始值，默认1）开始，以auto_increment_increment 为步长（默认1），持续叠加，直到找到第一个大于 X 的值，作为新的自增值。

在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要
求双写的时候，我们就可能会设置成auto_increment_increment=2，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突。

### 3 自增值的修改时机

```mysql
-- 表 t 里面已经有了 (1,1,1) 这条记录
insert into t values(null, 1, 1);
```

执行流程:

1. 执行器调用 InnoDB 引擎接口写入一行，传入的这一行的值是 (0,1,1);
2. InnoDB 发现用户没有指定自增 id 的值，获取表 t 当前的自增值 2；
3. 将传入的行的值改成 (2,1,1);
4. 将表的自增值改成 3；
5. 继续执行插入数据操作，由于已经存在 c=1 的记录，所以报 Duplicate key error，语句返回。

可以看到，这个表的自增值改成 3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键 c 冲突，所以 id=2 这一行并没有插入成功，但也没有将自增值再改回去。

#### 3.1 自增主键 id 不连续的原因

* 唯一键冲突
* 事务回滚
* 批量插入

### 4 自增锁的优化

自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。

在 MySQL 5.0 版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。

MySQL 5.1.22 版本引入了一个新策略，新增参数 innodb_autoinc_lock_mode，默认值是 1。

1. 这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁；

2. 这个参数的值被设置为 1 时：

   普通 insert 语句，自增锁在申请之后就马上释放；
   类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；

3. 这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。

类似 insert … select 这样的批量插入数据的语句导致的问题

binlog_format=statement，MS结构导致数据不一致。因为原库 session B 的 insert 语句，生成的 id 不连续。这个不连续的 id，用
statement 格式的 binlog 来串行执行，是执行不出来的。

对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：

1. 语句执行过程中，第一次申请自增 id，会分配 1 个；
2. 1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；
3. 2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4个；
4. 依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。

可如果没用完ID，就会导致自增 id 不连续

## 40 | insert语句的锁为什么这么多？

### 1 insert … select 语句

```mysql
-- 准备数据
CREATE TABLE `t` (
`id` int(11) NOT NULL AUTO_INCREMENT,
`c` int(11) DEFAULT NULL,
`d` int(11) DEFAULT NULL,
PRIMARY KEY (`id`),
UNIQUE KEY `c` (`c`)
) ENGINE=InnoDB;
insert into t values(null, 1,1);
insert into t values(null, 2,2);
insert into t values(null, 3,3);
insert into t values(null, 4,4);
create table t2 like t

```



| session A                       | session B                              |
| ------------------------------- | -------------------------------------- |
| insert into t values(-1,-1,-1); | insert into t2(c,d) select c,d from t; |

如果 session B 先执行，由于这个语句对表 t 主键索引加了 (-∞,1] 这
个 next-key lock，会在语句执行完成后，才允许 session A 的 insert 语句执行。如果没有锁，在 binlog_format=statement 的情况下，binlog 里面就记录了这样的语句序列：

```mysql
insert into t values(-1,-1,-1);
insert into t2(c,d) select c,d from t;
```

这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。

### 2 insert 循环写入

```mysql
-- 要往表 t2 中插入一行数据，这一行的 c 值是表 t 中 c 值的最大值加 1。
insert into t2(c,d) (select c+1, d from t force index(c) order by c desc limit 1);
```

这个语句的加锁范围，就是表 t 索引 c 上的 (3,4] 和 (4,supremum] 这两个 next-keylock，以及主键索引上 id=4 这一行。

执行流程：

从表 t 中按照索引 c 倒序，扫描第一行，拿到结果写入到表 t2中。因此整条语句的扫描行数是 1。

```mysql
-- 插入到表 t 中的话
insert into t(c,d) (select c+1, d from t force index(c) order by c desc limit 1);
-- Rows_examined 的值是 5。 using temporary
```

执行流程：

1. 创建临时表，表里有两个字段 c 和 d。
2. 按照索引 c 扫描表 t，依次取 c=4、3、2、1，然后回表，读到 c 和 d 的值写入临时表。这时，Rows_examined=4。
3. 由于语义里面有 limit 1，所以只取了临时表的第一行，再插入到表 t 中。这时，Rows_examined 的值加 1，变成了 5。

这个语句会导致在表 t 上做全表扫描，并且会给索引 c 上的所有间隙都加上共享的 next-key lock。所以，这个语句执行期间，其他事务不能在这个表上插入数据。

为什么需要临时表，原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。

优化方法：

先 insert into 到临时表 temp_t，这样就只需要扫描一行；然后再从表 temp_t 里面取出这行数据插入表 t1。

```mysql
create temporary table temp_t(c int,d int) engine=memory;
insert into temp_t (select c+1, d from t force index(c) order by c desc limit 1);
insert into t select * from temp_t;
drop table temp_t;
```

### 3 insert 唯一键冲突

| session A                                                    | session B                              |
| ------------------------------------------------------------ | -------------------------------------- |
| insert into t values(10,10,10)                               |                                        |
| begin; insert into t values(11,10,10);<br/>(Duplicate entry'10' for key 'c') |                                        |
|                                                              | insert into t values(12,9,9);(blocked) |

在可重复读（repeatable read）隔离级别下执行的。可以看到，session B要执行的 insert 语句进入了锁等待状态。

session A 执行的 insert 语句，发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁。

### 4 insert into … on duplicate key update

```mysql
insert into t values(11,10,10) on duplicate key update d=100;
-- 会给索引 c 上 (5,10] 加一个排他的 next-key lock（写锁）。
```

insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的
行。

## 41 | 怎么最快地复制一张表？

```mysql
-- 数据准备
create database db1;
use db1;
create table t(id int primary key, a int, b int, index(a))engine=innodb;
create database db2;
create table db2.t like db1.t
```

### 1 mysqldump 方法

```mysql
mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
```



这条命令中，主要参数含义如下：

1. –single-transaction 的作用是，在导出数据的时候不需要对表 db1.t 加表锁，而是使用
START TRANSACTION WITH CONSISTENT SNAPSHOT 的方法；
2. –add-locks 设置为 0，表示在输出的文件结果里，不增加" LOCK TABLES t WRITE;"
3. –no-create-info 的意思是，不需要导出表结构；
4. –set-gtid-purged=off 表示的是，不输出跟 GTID 相关的信息；
5. –result-file 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的。

生成语句如下

```mysql
INSERT INTO 't' values(901,901,901),(902,902,902)...
```

如果你希望生成的文件中一条 INSERT 语句只插入一行数据的话，可以在执行mysqldump 命令时，加上参数–skip-extended-insert。

```mysql
-- 将这些 INSERT 语句放到 db2 库里去执行。
mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"
```

 source 并不是一条 SQL 语句，而是一个客户端命令。mysql 客户端执行这个命令的流程是这样的： 

1. 打开文件，默认以分号为结尾读取一条条的 SQL 语句；
2. 将 SQL 语句发送到服务端执行。

### 2 导出 CSV 文件

```mysql
-- 导出csv语法如下
select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
```

注意如下几点:

1. 这条语句会将结果保存在服务端。如果你执行命令的客户端和 MySQL 服务端不在同一个机器上，客户端机器的临时目录下是不会生成 t.csv 文件的。

2. 这条命令不会帮你覆盖文件，因此你需要确保 /server_tmp/t.csv 这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。

3. 这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。但是，如果字段中包含换行符，在生成的文本中也会有换行符。不过类似换行符、制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。

4. into outfile 指定了文件的生成位置（/server_tmp/），这个位置必须受参数secure_file_priv 的限制。参数 secure_file_priv 的可选值和作用分别是：

  1. 如果设置为 empty，表示不限制文件生成的位置，这是不安全的设置；

  2. 如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；
  3. 设置为 NULL，就表示禁止在这个 MySQL 实例上执行 select … into outfile 操作。

```mysql
-- csv导入
load data infile '/server_tmp/t.csv' into table db2.t;
```

执行流程如下：

1. 打开文件 /server_tmp/t.csv，以制表符 (\t) 作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；

2. 启动事务。

3. 判断每一行的字段数与表 db2.t 是否相同：

   若不相同，则直接报错，事务回滚；

   若相同，则构造成一行，调用 InnoDB 引擎接口，写入到表中。

4. 重复步骤 3，直到 /server_tmp/t.csv 整个文件读入完成，提交事务。

#### 2.1 binlog_format=statement 执行流程如下：

1. 主库执行完成后，将 /server_tmp/t.csv 文件的内容直接写到binlog 文件中。
2. 往 binlog 文件中写入语句 load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTOTABLE `db2`.`t`。
3. 把这个 binlog 日志传到备库。
4. 备库的 apply 线程在执行这个事务日志时：
a. 先将 binlog 中 t.csv 文件的内容读出来，写入到本地临时目录
/tmp/SQL_LOAD_MB-1-0 中；
b. 再执行 load data 语句，往备库的 db2.t 表中插入跟主库相同的数据。

备库执行的 load data 语句里面，多了一个“local”。它的意思是“将执行这条命令的客户端所在机器的本地文件 /tmp/SQL_LOAD_MB-1-0 的内容，加载到目标表db2.t 中”。

load data 命令有两种用法：

1. 不加“local”，是读取服务端的文件，这个文件必须在 secure_file_priv 指定的目录或子目录下；
2. 加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程。

 **select …into outfile 方法不会生成表结构文件** 

```mysql
-- mysqldump 提供了一个–tab 参数，可以同时导出表结构定义文件和 csv 数据文件
-- 在 $secure_file_priv 定义的目录下，创建一个 t.sql 文件保存建表语句，同时创建一个 t.txt 文件保存 CSV 数据。
mysqldump -h$host -P$port -u$user ---single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --tab=$secure_file_priv
```

### 3 物理拷贝方法

在 MySQL 5.6 版本引入了可传输表空间(transportable tablespace) 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。

目标是在 db1 库下，复制一个跟表 t 相同的表 r，具体的执行步骤如下：

1. 执行 create table r like t，创建一个相同表结构的空表；
2. 执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；
3. 执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；
4. 在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；
5. 执行 unlock tables，这时候 t.cfg 文件会被删除；
6. 执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。

### 4 小结

对比一下这三种方法的优缺点。

1. 物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：

  必须是全表拷贝，不能只拷贝部分数据；

  需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；

  由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。

2. 用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where条件写法。

3. 用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。

## 42 | grant之后要跟着flush privileges吗？

```mysql
create user 'ua'@'%' identified by 'pa';
-- 语句的逻辑是创建一个用户’ua’@’%’，密码是 pa。
-- 在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 ua@ip1 和 ua@ip2 代表的是两个不同的用户。
```

这条命令做了两个动作：

1. 磁盘上，往 mysql.user 表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是 N；
2. 内存里，往数组 acl_users 里插入一个 acl_user 对象，这个对象的 access 字段值为 0。

### 1 全局权限

全局权限，作用于整个 MySQL 实例，这些权限信息保存在 mysql 库的 user 表里

```mysql
-- 给用户 ua 赋一个最高权限
grant all privileges on *.* to 'ua'@'%' with grant option;
```

执行流程：

1. 磁盘上，将 mysql.user 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为‘Y’；
2. 内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”。

结论：

1. grant 命令对于全局权限，同时更新了磁盘和内存。命令完成后即时生效，接下来新创建的连接会使用新的权限。
2. 对于一个已经存在的连接，它的全局权限不受 grant 命令的响。

```mysql
-- 回收权限
revoke all privileges on *.* from 'ua'@'%';
```

执行流程:

1. 磁盘上，将 mysql.user 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为“N”；
2. 内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 的值修改为 0。

### 2 db 权限

除了全局权限，MySQL 也支持库级别的权限定义.

```mysql
-- 让用户 ua 拥有库 db1 的所有权限
grant all privileges on db1.* to 'ua'@'%' with grant option;
```

基于库的权限记录保存在 mysql.db 表中，在内存里则保存在数组 acl_dbs 中。这条 grant命令做了如下两个动作：

1. 磁盘上，往 mysql.db 表中插入了一行记录，所有权限位字段设置为“Y”；
2. 内存里，增加一个对象到数组 acl_dbs 中，这个对象的权限位为“全 1”。

grant 修改 db 权限的时候，是同时对磁盘和内存生效的。

### 3 表权限和列权限

表权限定义存放在表 mysql.tables_priv 中，列权限定义存放在表 mysql.columns_priv 中。这两类权限，组合起来存放在内存的 hash 结构 column_priv_hash 中。

```mysql
create table db1.t1(id int, a int);
grant all privileges on db1.t1 to 'ua'@'%' with grant option;
GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO 'ua'@'%' with grant option;
```

跟 db 权限类似，这两个权限每次 grant 的时候都会修改数据表，也会同步修改内存中的hash 结构。因此，对这两类权限的操作，也会马上影响到已经存在的连接。

flush privileges 命令会清空 acl_users 数组，然后从 mysql.user 表中读取数据重新加载，重新构造一个 acl_users 数组。也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。

#### 4 flush privileges 使用场景

当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges 语句可以用来重建内存数据，达到一致状态。

### 5 小结

1. grant 语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用 grant 和 revoke 语句，是不需要随后加上 flush privileges 语句的。

2. flush privileges 语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用 DML 语句操作系统权限表导致的

3. grant super on *.* to 'ua'@'%' identified by 'pa';

   grant super on *.* to 'ua'@'%' identified by 'pa';

   如果用户 ua 已经存在，就将密码修改成 pa。

## 43 | 要不要使用分区表？

### 1 分区表是什么？

## 45 | 自增id用完怎么办？

### 1 表定义自增值 id

表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。

```mysql
create table t(id int unsigned auto_increment primary key) auto_increment=4294967295;
insert into t values(null);
// 成功插入一行 4294967295
show create table t;
/* CREATE TABLE `t` (
`id` int(10) unsigned NOT NULL AUTO_INCREMENT,
PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=4294967295;
*/
insert into t values(null);
//Duplicate entry '4294967295' for key 'PRIMARY'
```

第一个 insert 语句插入数据成功后，这个表的 AUTO_INCREMENT 没有改变（还是 4294967295），就导致了第二个 insert 语句又拿到相同的自增 id 值，再试图执行插入语句，报主键冲突错误。

### 2 InnoDB 系统自增 row_id

你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为6 个字节的 row_id。InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的InnoDB 表，每插入一行数据，都将当前的 dict_sys.row_id 值作为要插入数据的 row_id，然后把 dict_sys.row_id 的值加 1。

实际上，在代码实现时 row_id 是一个长度为 8 字节的无符号长整型 (bigint unsigned)。但是，InnoDB 在设计时，给 row_id 留的只是 6 个字节的长度；特征：

1. row_id 写入表中的值范围，是从 0 到 2^48 -1；
2. 当 dict_sys.row_id=2^48 时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是 0。

如果一个 MySQL 实例跑得足够久的话，还是可能达到这个上限（2^48）的。在 InnoDB 逻辑里，申请到 row_id=N 后，就将这行数据写入表中；如果表中已经存在 row_id=N 的行，新写入的行就会覆盖原有的行。

### 3 Xid

redo log 和binlog 相配合的时候，提到了它们有一个共同的字段叫作 Xid。它在 MySQL 中是用来对应事务的。

MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。

global_query_id 是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。

MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。

如果global_query_id 达到上限后，就会继续从 0 开始计数。从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景。

### 4 Innodb trx_id

